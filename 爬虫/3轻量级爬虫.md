[TOC]



**只涉及相对简单的部分，具体内容参考文档**

----

**“获取数据——解析数据——存储数据”**是爬虫的三部曲，大部分爬虫都是按这样的流程来进行，这其实也是模拟了我们使用浏览器获取网页信息的过程。

### 获取数据

​		**爬虫第一步操作就是模拟浏览器向服务器发送请求**，基于python，你不需要了解从数据的实现，HTTP、TCP、IP的网络传输结构，一直到服务器响应和应答的原理，因为**python提供了功能齐全的类库来帮我们完成这些请求。**

python提供的类库有很多，这里举常用的例子介绍



---------------------------------------



#### urllib3

官方使用文档：[User Guide - urllib3 2.1.0 documentation](https://urllib3.readthedocs.io/en/stable/user-guide.html)

##### PoolManager

​	使用urllib3发送网络请求时，需要首先创建PoolManager对象，再通过该对象调用 **request()** 方法发送请求。

```python
urllib3.disable_warnings() #关闭ssl警告
http = urllib3.PoolManager()
```

PoolManager有很多可选参数：

- `num_pools`：指定连接池的数量，默认为 10。连接池数量决定了可以同时保持多少个**域名**连接。
- `maxsize`：指定每个连接池的最大连接数，默认为 None，表示不限制。如果设置为一个正整数，则会限制每个连接池的最大连接数。
- `block`：当连接池中没有可用连接时，是否阻塞等待，默认为 False。如果设置为 True，则在连接池占满时，请求会被阻塞，直到有可用连接为止。如果设置为 False，则在连接池占满时，会抛出一个异常。
- `timeout`：设置连接超时时间，默认为 None，表示不限制。可以设置一个浮点数，指定连接的超时时间，单位为秒。
- `retries`：设置重试重定向次数，默认为 3。当发起请求时，如果出现连接错误或超时，会自动进行一定次数的重试。
- `headers`：请求头参数，默认为空字典。若设置，则之后的请求默认加入这些header

###### 连接池

​		连接池（Connection Pool）是一种缓存技术，用于重复利用已建立的连接，以提高应用程序的性能和可伸缩性。连接池预先创建一定数量的连接，并将其保存在内存中，以备后续使用，避免了每次请求都重新建立连接的开销。

**num_pools**

指定池子的数量, 假如有10个池子, 当你访问第11个域名的时候第一个池子会被干掉, 然后建一个新的供第11个使用.一个池子是作用于同一个域名下的, 即http://aaa.com/a和http://aaa.com/b是会共用一个池子的



**maxsize**

指定一个池子缓存的最大连接数量.没有超过最大链接数量的链接都会被保存下来.在block为false的情况下,             添加的额外的链接不会被保存一般多用于多线程之下, 一般情况是设置为和线程数相等的数量, 保证每个线程都能访问一个链接. 



##### 发送请求

​		urllib3发送请求可以使用urlopen和request，一般用request

```python
request(method,url,fields=None,headers=None)
```

- `method` 必选参数，用于指定请求方式，如GET，POST，PUT等。
- `url` 必须按参数，要访问的url
- `fields` 可选参数，设置请求的参数
- `headers` 可选参数，请求头

同样也可以设置timeout、retries等



##### 响应内容

###### 响应头

可以通过info（）方法获取响应头，也可以直接获取

```python
response = poolManager.request()
response_headers = response.info()#得到一个响应头字典
response_headers = response.headers#同上
```

###### JSON

导入json模块将JSON格式转化为字典

```python
json.loads(response.data.decode('unicode_escape')) # unicode_escape处理中文
```



###### 二进制格式

这种一般就是图片，举个例子

```python
import urllib3

url = 'https://www.bing.com/red-dot-24.png'
http = urllib3.PoolManager()
response = http.request('GET', url)
f = open('red-dot-24.png', 'wb')#wb是以二进制格式写入模式打开文件
f.write(response.data)#写入数据
f.close()#关闭文件
```



##### 上传内容

将文件转化为data后上传

两种方法，一种传fields，一种传body

fields只适合上传小规模、不涉及敏感信息的文本

body更适合传输大规模传输，给以传输更多类型的数据

###### 文本上传

```python
#fields
url = 'http://httpbin.org/post'
with open('Person.txt','r') as f : # 创建一个文件流
    data = f.read()
response = http.request('POST',url,fields={'filefield':('Person',data,'txt')})
print(response.data.decode())

#body
url = 'http://httpbin.org/post'
with open('Person.txt','r') as f :
    data = f.read()
response = http.request('POST',url,body = data)
print(response.data.decode())
```



###### JSON

```python
url = 'http://httpbin.org/post'
params = json.dumps({'name':'杰克','age':'23'})
response = http.request('POST',url,body=params)#这里body也可以替换成json
print(response.data.decode('unicode_escape'))
```



###### 图片上传

类似文本，但需要表明请求头Content-Type

```python
url = 'http://httpbin.org/post'
with open('red-dot-24.png','rb') as f :
    data = f.read()
response = http.request('POST',url,body=data,headers={'Content-Type':'image/jpeg'})
print(response.data.decode())
```

###### cookies

urllib3上传cookie要把cookie添加在请求头中

相应的，返回的cookie从响应头中获取

```python
header = {'cookie':'work'}

response = http.request()
cookie = response.headers
```



##### 代理

设置代理IP需要创建ProxyManager对象，该对象需要有两个参数；proxy_url表示需要使用的代理IP，headers即请求头。

```python
proxy = urllib3.ProxyManager('xxxxxxxxxxxx', headers=headers)
r = proxy.request('get', url)  # 发送请求
```



---------------------------------------



#### requests

​		`requests` 被设计为更加简洁和易用的 HTTP 库。它提供了简洁的 API，易于学习和使用。`requests` 的目标是提供一种直观和方便的方式来执行各种 HTTP 请求，并在背后处理许多细节。

`requests` 利用了 `urllib3` 提供的底层 HTTP 连接和细节，同时提供了更简洁、更高级的 API，使得发送 HTTP 请求变得更加容易。

官方文档：[Quickstart — Requests 2.31.0 documentation](https://requests.readthedocs.io/en/latest/user/quickstart/)

​		使用requests非常简便

```python
import requests

url = 'https://httpbin.org/get'
response = requests.get(url)

url = 'https://httpbin.org/post'
r = requests.post(url,data={'key':'value'})

r = requests.put('https://httpbin.org/put', data={'key': 'value'})
r = requests.delete('https://httpbin.org/delete')
r = requests.head('https://httpbin.org/get')
r = requests.options('https://httpbin.org/get')
r.encoding = 'unicode_escape'#解码格式改为unicode_escape来处理中文
print(r.text) #获取解码后的响应内容
print(r.content)#获取原始内容 

r = requests.get(url,params={'key':'value'})#params会作为查询字符串添加到url上
print(r.url)#获取url

r = requests.get(url,timeout=1)#设置超时时间，不设置则默认不会超时。
#注意：超时指的不是整个请求过程花费时间，而是在设置的超时时间内没有收到传来的字节时认定超时
```

##### params注意事项

- 任何为空的value值都不会添加到url中

- 针对同一个key，可以上传多个value，通过列表的形式

  ```python
  payload = {'key1': 'value1', 'key2': ['value2', 'value3']}
  r = requests.get('https://httpbin.org/get', params=payload)
  print(r.url)
  #result:
  #https://httpbin.org/get?key1=value1&key2=value2&key2=value3
  ```

##### text和 content的区别

**text**会自动对响应内容进行默认为**‘utf-8’**格式的解码，而**content**不会对响应内容进行任何更改

如果响应内容为**HTML、JSON**等，**text**更好

如果响应内容为**图片等二进制**内容，使用**content**来获取图片二进制数据

例如，以下为请求图片内容时text和content的数据对比（上部分为text，下部分为content）

```python
���� JFIF      ��!�ICC_PROFILE   !�NKON   mntrRGB XYZ �     
 !#$&')*,./124679:<>?ACDFGIKLNPQSUWXZ\]_acdfhjkmoqrtvxz{}������������������������������������

b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x00\x00\x01\x00\x01\x00\x00\xff\xe2!\xfcICC_PROFILE\x00\x01\x01\x00\x00!\xecNKON\x02 \x00\x00mntrRGB XYZ \x07\xd9\x00\x02\x00\x14\x00\x11\x00\x07\x00\nacspAPPL\x00\x00\x00\x00none\x00\x00\x00\x01\x00\x00\x0
```

content数据以b'开头，表示是二进制数据

##### JSON

​	requests有内置json解码器

```python
r = requests.get(url)
r.json()
```

如果返回内容不是JSON格式，则会报错

需要上传JSON格式的话

```python
data = {'key':'value'}
r = requests.post(url,json=data)
```

**注意:**如果上传json同时上传了data或files，json会被忽略

##### cookies

上传cookie

```python
url = 'https://httpbin.org/cookies'
cookies = dict(cookies_are='working')

r = requests.get(url, cookies=cookies)
print(r.text)
```



-----

##### 文件

​		requests上传文件非常简便

```python
url = 'https://httpbin.org/post'
files = {'file':open('person.txt','rb')}
r = requests.post(url,files=files)


#还可以直接编辑需要上传的内容
url = 'https://httpbin.org/post'
files = {'file':('c.txt','some data to send')}
r = requests.post(url,files=files)

#图片
url = 'https://httpbin.org/post'
files = {'image':('test.png',open('test.png','rb'),'image/png')}
```

**注意：**在requests的官方文档中有如下警告：

It is strongly recommended that you open files in [binary mode](https://docs.python.org/3/tutorial/inputoutput.html#tut-files). This is because Requests may attempt to provide the `Content-Length` header for you, and if it does this value will be set to the number of *bytes* in the file. Errors may occur if you open the file in *text mode*.

因此在打开文件进行上传时尽量以rb方式打开

##### 响应内容

######  响应状态码

```python
code = r.status_code # 200,304...

#requests内置了各种请求状态码
if code = requests.codes.ok:
    print('ok')


try:
    r.raise_for_status()
    # 如果没有异常，继续处理正常响应
    print("ok")
except requests.exceptions.HTTPError as err:
    # 处理 HTTP 错误
    print(err)

#该方法会检查是否请求失败
```

###### 响应头

```python
headers = r.headers # 返回header字典
```

###### cookies

如果请求结果中包含了cookies，可以使用以下方法获取

```python
cookieJar = r.cookies
```

用如下方法上传cookie键值对

```python
myCookie = {'cookie_name':'value'}
requests.get(url,cookies=myCookie)
```

当然，requests是在urllib3基础上建立的，也可以在header上直接上传cookie



##### 重定向

requests会自动处理head请求外的所有重定向

```python
history = response.history # 获取所有response的list,从最早的响应到最近的响应

r = requests.get('http://github.com/', allow_redirects=False) # 禁用重定向

r = requests.head('http://github.com/', allow_redirects=True)#head请求重定向需要自行启用
```



-----

#### 关于urllib3和requests的cookie上传

注意到urllib3上传cookie直接在请求头中以key为Cookie，值为value的形式上传，而requests上传cookie可以上传字典，而字典中包含一个cookie_name。

**cookie**是由一系列的键值对组成的，举个例子

```
MUID=33C3DEA78AE06D390BD2CDBD8B866C50; SRCHD=AF=NOFORM; SRCHUID=V=2&GUID=373FF788DD824FD7A3560E5193705AB0&dmnchg=1; MUIDB=33C3DEA78AE06D390BD2CDBD8B866C50; PPLState=1;
```

分号划分每个键值对，MUID即为cookie_name,33C3DEA78AE06D390BD2CDBD8B866C50即为value。

requests的的cookie上传的字典可以包含多个键值对，在请求时将会自动处理后加入header中

也就是说

```python
http.request(method='get',header={'Cookie':'id=1;name=Jack'})

requests.get(url,cookies={'id':1,'name':'Jack'})
```

作用相同



---



#### 使用requests爬取ccnu一站式平台获取用户信息

```python
import requests
import re
import time
from datetime import datetime
import User

s = requests.Session()


headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0',
}
url = 'https://account.ccnu.edu.cn/cas/login'

s.headers = headers
data = {'username':User.id,
        'password':User.password,
        '_eventId':'submit',
        'submit':'登录',
        'execution':'',
        'lt':''
        }

r = s.get(url,params={'service':'http://one.ccnu.edu.cn/cas/login_portal'})
ltText = r.text
lt = re.search(r'<input type="hidden" name="lt" value="(.*?)" />',ltText)

execution = re.search(r'<input type="hidden" name="execution" value="(.*?)" />',ltText)
print(execution.group(1))
params = {'service':'http://one.ccnu.edu.cn/cas/login_portal'}

data.update({'lt':lt.group(1)})
data.update({'execution':execution.group(1)})

s.cookies.update({'CASPRIVACY':'', 'CASTGC':''})
r = s.post(url,data=data,params=params,allow_redirects=True)

timestamp_milliseconds = int(datetime.now().timestamp() * 1000)

data = {'limit':'10','page':'1','tranType':'','start':'2023-11-18','end':'2023-11-24'}
s.headers.update({'Authorization':f'Bearer {s.cookies["PORTAL_TOKEN"]}'})
r = s.post('http://one.ccnu.edu.cn/user_portal/index')
print(r.text)
```



#### 爬教务管理系统

```python
import requests
import re
import time
from datetime import datetime
import User

s = requests.Session()


headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0',
}
url = 'https://account.ccnu.edu.cn/cas/login'

s.headers = headers
data = {'username':User.id,
        'password':User.password,
        '_eventId':'submit',
        'submit':'登录',
        'execution':'',
        'lt':''
        }

# 与一站式唯一不同的就是service
r = s.get(url,params={'service':'http://xk.ccnu.edu.cn/sso/pziotlogin'})
ltText = r.text
lt = re.search(r'<input type="hidden" name="lt" value="(.*?)" />',ltText)

execution = re.search(r'<input type="hidden" name="execution" value="(.*?)" />',ltText)
print(execution.group(1))

data.update({'lt':lt.group(1)})
data.update({'execution':execution.group(1)})

s.cookies.update({'CASPRIVACY':'', 'CASTGC':''})
r = s.post(url,data=data,params={'service':'http://xk.ccnu.edu.cn/sso/pziotlogin'},allow_redirects=True)

print(r.status_code)
print(r.headers)
print(s.headers)
for p in r.history:
        print(p.url)
        print(p.headers)

print(s.cookies)
# 获取到token和jsessionid，就能爬平时成绩、选课、考试安排之类的
```

